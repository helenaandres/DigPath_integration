{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "#from functions_extract_measures_catalogues import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./76479.fits\n",
      "^good\n",
      "shape mean (345130,)\n",
      "shape T (345130,)\n",
      "num cell types 4\n",
      "Saving null values for marks/cell type  0\n",
      "1\n",
      "2\n",
      "3\n",
      "        X_global  Y_global  area_cnt  area_minCircle  area_ellipse  perimeter  \\\n",
      "0       0.000000  0.000000  0.000000        0.000000      0.000000   0.000000   \n",
      "1       0.000000  0.000000  0.000000        0.000000      0.000000   0.000000   \n",
      "2       0.168876  0.125754  0.105714        0.076664      0.069881   0.123749   \n",
      "3       0.121634  0.141590  0.121281        0.042384      0.067691   0.090225   \n",
      "4       0.000000  0.000000  0.000000        0.000000      0.000000   0.000000   \n",
      "...          ...       ...       ...             ...           ...        ...   \n",
      "345125  0.344615  0.275274  0.040591        0.038264      0.026123   0.057486   \n",
      "345126  0.256850  0.283120  0.045517        0.031901      0.025423   0.065158   \n",
      "345127  0.277101  0.283142  0.022266        0.020872      0.019126   0.043788   \n",
      "345128  0.364856  0.314557  0.140394        0.127350      0.079441   0.149620   \n",
      "345129  0.385065  0.298687  0.120493        0.043525      0.065787   0.094513   \n",
      "\n",
      "        eqDiamater    extent  ell_angle  ell_majorAxis  ...  fluxStd_a  \\\n",
      "0         0.000000  0.000000   0.000000       0.000000  ...   0.000000   \n",
      "1         0.000000  0.000000   0.000000       0.000000  ...   0.000000   \n",
      "2         0.152212  0.171254   0.214954       0.129337  ...   0.134640   \n",
      "3         0.185371  0.099170   0.186838       0.102610  ...   0.061333   \n",
      "4         0.000000  0.000000   0.000000       0.000000  ...   0.000000   \n",
      "...            ...       ...        ...            ...  ...        ...   \n",
      "345125    0.075169  0.149795   0.341544       0.093134  ...   0.089236   \n",
      "345126    0.093363  0.118573   0.244021       0.072274  ...   0.079346   \n",
      "345127    0.046913  0.136838   0.288361       0.059219  ...   0.063927   \n",
      "345128    0.207428  0.109080   0.460581       0.200890  ...   0.047877   \n",
      "345129    0.173786  0.083133   0.254103       0.083226  ...   0.106692   \n",
      "\n",
      "        fluxStd_b     Hu_01     Hu_02     Hu_03     Hu_04     Hu_05     Hu_06  \\\n",
      "0        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "1        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2        0.112319  0.073158  0.037062  0.003341  0.000575  0.000004  0.000126   \n",
      "3        0.070663  0.041318  0.017014  0.002725  0.001253  0.000016  0.000425   \n",
      "4        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "345125   0.102399  0.055285  0.027240  0.004582  0.002466  0.000058  0.001132   \n",
      "345126   0.079947  0.048113  0.016953  0.008258  0.001924  0.000020  0.000152   \n",
      "345127   0.088439  0.040084  0.011072  0.007854  0.001702  0.000019  0.000091   \n",
      "345128   0.159285  0.083061  0.037097  0.008528  0.004407  0.000147  0.001399   \n",
      "345129   0.195900  0.045271  0.018617  0.002583  0.000517  0.000003  0.000157   \n",
      "\n",
      "           Hu_07       s2n  \n",
      "0       0.000000  0.000000  \n",
      "1       0.000000  0.000000  \n",
      "2       0.000018  0.144198  \n",
      "3       0.000058  0.126949  \n",
      "4       0.000000  0.000000  \n",
      "...          ...       ...  \n",
      "345125  0.000202  0.093515  \n",
      "345126  0.001325  0.049328  \n",
      "345127  0.001327  0.047583  \n",
      "345128  0.000246  0.077103  \n",
      "345129  0.000014  0.118699  \n",
      "\n",
      "[345130 rows x 46 columns]\n",
      "shape d_mean (345130, 46)\n",
      "shape df (345130, 63)\n",
      "saving median...\n"
     ]
    }
   ],
   "source": [
    "### ADD HEADER ###\n",
    "X_t=Table.read('/home/ICM_CG/Projects/METABRIC/level2_catalogues/76479.fits', format='fits')\n",
    "\n",
    "K=10\n",
    "print('./76479.fits')\n",
    "print('^good')\n",
    "\n",
    "filename = \"./results/simil_measures_k10.txt\"\n",
    "T_d, T_d_ind_mean, T_d_ind_std  = add_density(X_t, bandwidth = int(K))\n",
    "\n",
    "rho_cells_medians, S_mean_cells_medians, S_std_cells_medians, Sf_mean_cells_medians, Sf_std_cells_medians = calculate_medians(T_d,T_d_ind_mean, T_d_ind_std, cell_type = True, k =int(K))\n",
    "print('saving median...')\n",
    "\n",
    "header = np.column_stack(('ID', 'img_Rho_CC', 'img_Rho_L', 'img_Rho_NC','img_S_mean_CC', 'img_S_mean_L', 'img_S_mean_NC',\n",
    "                          'img_S_std_CC', 'img_S_std_L', 'img_S_std_NC'))\n",
    "\n",
    "h_1_mean = ['img_V_'+i+'_CC_mean' for i in Sf_mean_cells_medians[1].keys().values]\n",
    "h_2_mean = ['img_V_'+i+'_L_mean' for i in Sf_mean_cells_medians[2].keys().values]\n",
    "h_3_mean = ['img_V_'+i+'_NC_mean' for i in Sf_mean_cells_medians[3].keys().values]\n",
    "h_1_std = ['img_V_'+i+'_CC_std' for i in Sf_mean_cells_medians[1].keys().values]\n",
    "h_2_std = ['img_V_'+i+'_L_std' for i in Sf_mean_cells_medians[2].keys().values]\n",
    "h_3_std = ['img_V_'+i+'_NC_std' for i in Sf_mean_cells_medians[3].keys().values]\n",
    "\n",
    "header_full = np.column_stack((header, np.array(h_1_mean).reshape(1,46), np.array(h_1_std).reshape(1,46),\n",
    "                               np.array(h_2_mean).reshape(1,46), np.array(h_2_std).reshape(1,46),\n",
    "                               np.array(h_3_mean).reshape(1,46), np.array(h_3_std).reshape(1,46),))\n",
    "\n",
    "#A = np.concatenate((np.array([Y]), np.array(rho_cells_medians)[1:],np.array(S_mean_cells_medians)[1:],\n",
    "#                    np.array(S_std_cells_medians)[1:], Sf_mean_cells_medians[1].values, \n",
    "#                    Sf_std_cells_medians[1].values, Sf_mean_cells_medians[2].values, \n",
    "#                    Sf_std_cells_medians[2].values,Sf_mean_cells_medians[3].values, \n",
    "#                    Sf_std_cells_medians[3].values))\n",
    "#A = np.column_stack((A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1931, 286)\n",
      "(1, 286)\n"
     ]
    }
   ],
   "source": [
    "data_imgs= pd.read_csv('simil_measures_k10.txt', header=None, delimiter = ' ')\n",
    "\n",
    "#data_imgs.columns=header_full\n",
    "data_imgs.columns=header_full[0]\n",
    "print(data_imgs.values.shape)\n",
    "print(header_full.shape)\n",
    "#print(data_imgs)\n",
    "data_imgs.to_csv('simil_measures_k10_col.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imgs['ID'].unique().shape\n",
    "data_imgs_unique = data_imgs.drop_duplicates(subset=['ID'], keep='first')\n",
    "#print(data_imgs_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     METABRIC.ID  invasion non_invasive              benign  \\\n",
      "0        MB-0000   present         DCIS                 NaN   \n",
      "1        MB-0002   present         DCIS                 NaN   \n",
      "2        MB-0005   present         DCIS                 NaN   \n",
      "3        MB-0006   present         DCIS  ColumnarCellChange   \n",
      "4        MB-0008   present         DCIS                 NaN   \n",
      "...          ...       ...          ...                 ...   \n",
      "1665     MB-5648   present          NaN                 NaN   \n",
      "1666     MB-5651  present           NaN                 NaN   \n",
      "1667     MB-5653   present          NaN                 NaN   \n",
      "1668     MB-5654   present          NaN                 NaN   \n",
      "1669     MB-5656  present           NaN                 NaN   \n",
      "\n",
      "     lymphocytic_infiltrate      LVI             tumour_type  mitotic_score  \\\n",
      "0                      mild   absent                     NST            2.0   \n",
      "1                      mild   absent                     NST            1.0   \n",
      "2                      mild   absent                     NST            2.0   \n",
      "3                      mild  present  MixedNSTandSpecialType            1.0   \n",
      "4                      mild  present  MixedNSTandSpecialType            2.0   \n",
      "...                     ...      ...                     ...            ...   \n",
      "1665                 absent   absent                     NST            1.0   \n",
      "1666                  mild   absent      MixedNSTandLobular             1.0   \n",
      "1667                 absent   absent                     NST            1.0   \n",
      "1668                 absent   absent                     NST            1.0   \n",
      "1669                absent   absent                     NST             1.0   \n",
      "\n",
      "      nuc_pleomorphism_score  tubule.formation_score  total_score  \\\n",
      "0                        3.0                     2.0          7.0   \n",
      "1                        3.0                     3.0          7.0   \n",
      "2                        3.0                     3.0          8.0   \n",
      "3                        3.0                     3.0          7.0   \n",
      "4                        3.0                     3.0          8.0   \n",
      "...                      ...                     ...          ...   \n",
      "1665                     2.0                     3.0          6.0   \n",
      "1666                     3.0                     3.0          7.0   \n",
      "1667                     3.0                     3.0          7.0   \n",
      "1668                     3.0                     3.0          7.0   \n",
      "1669                     2.0                     3.0          6.0   \n",
      "\n",
      "      overall_grade                     comments  \n",
      "0               2.0                          NaN  \n",
      "1               2.0                          NaN  \n",
      "2               3.0                          NaN  \n",
      "3               2.0        Special type apocrine  \n",
      "4               3.0  Special type micropapillary  \n",
      "...             ...                          ...  \n",
      "1665            2.0                          NaN  \n",
      "1666            2.0                          NaN  \n",
      "1667            2.0  Few fields to count mitoses  \n",
      "1668            2.0                          NaN  \n",
      "1669            2.0                          NaN  \n",
      "\n",
      "[1670 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#data_medical= pd.read_csv('/home/ICM_CG/Projects/METABRIC/CL_Image_analysis/MBdata_33CLINwMiss_1KfGE_1KfCNA.csv')\n",
    "data_medical= pd.read_csv('/home/ICM_CG/Projects/METABRIC/DigPath_integration/data/MBdata_33CLINwMiss_1KfGE_1KfCNA_2.csv')\n",
    "data_medical_oscar= pd.read_csv('/home/ICM_CG/Projects/METABRIC/DigPath_integration/data/FullPath_METABRIC.txt', sep='\\t', low_memory=False)\n",
    "print(data_medical_oscar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413\n",
      "(1413, 2319)\n",
      "(1398, 2331)\n"
     ]
    }
   ],
   "source": [
    "ids = [i for i in data_imgs_unique['ID']]\n",
    "#data_idx_intersect = np.intersect1d(data_medical['METABRIC_ID'],data_imgs_unique['ID'])\n",
    "#data_intersect = data_medical.loc[data_medical['METABRIC_ID'].isin(data_idx_intersect)]\n",
    "#print('There are ' ,data_intersect.shape[0], 'patients with all data modalities')\n",
    "print(len(ids))\n",
    "\n",
    "#for i in ids: \n",
    "#    print(data_medical.loc[data_medical['METABRIC_ID'] == i])\n",
    "\n",
    "    \n",
    "#data_combo = data_imgs_unique.merge(data_medical, on=[\"METABRIC_ID\", \"ID\"]) \n",
    "data_medical = data_medical.rename(columns={\"METABRIC_ID\": \"ID\"})\n",
    "data_oscar = data_medical_oscar.rename(columns={\"METABRIC.ID\": \"ID\"})\n",
    "#print(data_medical)\n",
    "data_combo = pd.merge(data_imgs_unique, data_medical, on='ID')\n",
    "print(data_combo.shape)\n",
    "data_combo = pd.merge(data_combo, data_oscar, on='ID')\n",
    "print(data_combo.shape)\n",
    "\n",
    "data_combo.to_csv('newIDs_data_combined_unique_k10.csv', index=False)\n",
    "    #print(np.where(data_medical['METABRIC_ID'].values==i))\n",
    "    #print(data_medical.where(data_medical['METABRIC_ID']==i))\n",
    "    \n",
    "#for i in ids:\n",
    "#    print(i)\n",
    "#    print(data_medical['METABRIC_ID'].any()==i)\n",
    "    #if data_medical['METABRIC_ID'].any()==i:\n",
    "    #    data_medical_unique = data_medical[data_medical.iloc(data_medical[['METABRIC_ID']==i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['s2n_NC_std', 'Cohort', 'Age_At_Diagnosis', 'Breast_Tumour_Laterality',\n",
      "       'Date_Of_Diagnosis', 'Last_Followup_Status', 'NPI', 'ER_Status',\n",
      "       'Inferred_Menopausal_State', 'Lymph_Nodes_Positive', 'Breast_Surgery',\n",
      "       'CT', 'HT', 'RT', 'Grade', 'Size', 'Histological_Type', 'Stage',\n",
      "       'Cellularity', 'DeathBreast', 'Death', 'clin_T', 'TLR', 'LR', 'TDR',\n",
      "       'DR', 'HER2_SNP6', 'iC10', 'Pam50Subtype', 'ER_Expr', 'Her2_Expr',\n",
      "       'PR_Expr', 'ClaudinSubtype', 'Complete_Rec_History', 'GE_GRB7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_combo.columns[285:320])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from astroML.density_estimation import KNeighborsDensity\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from astropy.table import Table, vstack\n",
    "import sys, os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import special\n",
    "from sklearn.neighbors import BallTree\n",
    "from scipy.spatial.distance import cdist\n",
    "import csv\n",
    "\n",
    "def n_volume(r, n):\n",
    "    \"\"\"compute the n-volume of a sphere of radius r in n dimensions\"\"\"\n",
    "    return np.pi ** (0.5 * n) / special.gamma(0.5 * n + 1) * (r ** n)\n",
    "\n",
    "def similarity(ind, X_f, matrix=False, indiv=False):\n",
    "    if matrix == True: #output similarity matrix\n",
    "        d_m=[cdist(np.array(X_f[ind[i,:],:]),np.array(X_f[ind[i,:],:])) for i in ind]\n",
    "    else: \n",
    "        d_m=0\n",
    "        min_Xf = np.array([np.amin(np.array(X_f[:,i])) for i in np.arange(X_f.shape[1])]) \n",
    "        X_f = (X_f - min_Xf)\n",
    "        max_Xf = np.array([np.amax(np.array(X_f[:,i])) for i in np.arange(X_f.shape[1])]) \n",
    "        X_f = X_f / max_Xf    \n",
    "        \n",
    "    if indiv == True:\n",
    "\n",
    "        d=[np.sqrt((np.array(X_f[ind[i,:]]) - np.array([X_f[ind[i,0]]]))**2) for i in ind[:,0]]\n",
    "        D = [np.mean(np.array(d),axis=1),np.std(np.array(d),axis=1)]\n",
    "\n",
    "    elif indiv == False: #compute similarity for all features\n",
    "        \n",
    "        d=[cdist(np.array([X_f[ind[i,0],:]]),np.array(X_f[ind[i,:],:])) for i in ind[:,0]]\n",
    "        D = [np.mean(np.array(d),axis=2),np.std(np.array(d),axis=2)]\n",
    "        \n",
    "    return D, d_m\n",
    "    \n",
    "class KNeighborsDensity_modified(object):\n",
    "    \"\"\"K-neighbors density estimation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : string\n",
    "        method to use.  Must be one of ['simple'|'bayesian'] (see below)\n",
    "    n_neighbors : int\n",
    "        number of neighbors to use\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The two methods are as follows:\n",
    "\n",
    "    - simple:\n",
    "        The density at a point x is estimated by n(x) ~ k / r_k^n\n",
    "    - bayesian:\n",
    "        The density at a point x is estimated by n(x) ~ sum_{i=1}^k[1 / r_i^n].\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    KDE : kernel density estimation\n",
    "    \"\"\"\n",
    "    def __init__(self, method='bayesian', n_neighbors=10):\n",
    "        if method not in ['simple', 'bayesian']:\n",
    "            raise ValueError(\"method = %s not recognized\" % method)\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"Train the K-neighbors density estimator\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array_like\n",
    "            array of points to use to train the KDE.  Shape is\n",
    "            (n_points, n_dim)\n",
    "        \"\"\"\n",
    "        self.X_ = np.atleast_2d(X)\n",
    "        if self.X_.ndim != 2:\n",
    "            raise ValueError('X must be two-dimensional')\n",
    "\n",
    "        self.bt_ = BallTree(self.X_)\n",
    "        return self\n",
    "\n",
    "    def eval(self, X, X_f):\n",
    "        \"\"\"Evaluate the kernel density estimation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array_like\n",
    "            array of points at which to evaluate the KDE.  Shape is\n",
    "            (n_points, n_dim), where n_dim matches the dimension of\n",
    "            the training points.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dens : ndarray\n",
    "            array of shape (n_points,) giving the density at each point.\n",
    "            The density will be normalized for metric='gaussian' or\n",
    "            metric='tophat', and will be unnormalized otherwise.\n",
    "        \"\"\"\n",
    "        self.X_f = X_f\n",
    "        X = np.atleast_2d(X)\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError('X must be two-dimensional')\n",
    "\n",
    "        if X.shape[1] != self.X_.shape[1]:\n",
    "            raise ValueError('dimensions of X do not match training dimension')\n",
    "\n",
    "        dist, ind = self.bt_.query(X, self.n_neighbors, return_distance=True)\n",
    "\n",
    "        #measure similarity with neighbors \n",
    "        D, d_m=similarity(ind, self.X_f)\n",
    "        \n",
    "        k = float(self.n_neighbors)\n",
    "        ndim = X.shape[1]       \n",
    "\n",
    "        if self.method == 'simple':\n",
    "            dens = k / n_volume(dist[:, -1], ndim)\n",
    "\n",
    "        elif self.method == 'bayesian':\n",
    "            # XXX this may be wrong in more than 1 dimension!\n",
    "            dens =  (k * (k + 1) * 0.5 / n_volume(1, ndim)\n",
    "                    / (dist ** ndim).sum(1))            \n",
    "        else:\n",
    "            raise ValueError(\"Unrecognized method '%s'\" % self.method)\n",
    "        return dens, D\n",
    "            \n",
    "    def eval_indiv_feat(self, X, X_f):\n",
    "        \"\"\"Evaluate the kernel density estimation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array_like\n",
    "            array of points at which to evaluate the KDE.  Shape is\n",
    "            (n_points, n_dim), where n_dim matches the dimension of\n",
    "            the training points.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dens : ndarray\n",
    "            array of shape (n_points,) giving the density at each point.\n",
    "            The density will be normalized for metric='gaussian' or\n",
    "            metric='tophat', and will be unnormalized otherwise.\n",
    "        \"\"\"\n",
    "        self.X_f = X_f\n",
    "        X = np.atleast_2d(X)\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError('X must be two-dimensional')\n",
    "\n",
    "        if X.shape[1] != self.X_.shape[1]:\n",
    "            raise ValueError('dimensions of X do not match training dimension')\n",
    "\n",
    "        dist, ind = self.bt_.query(X, self.n_neighbors, return_distance=True)\n",
    "\n",
    "        \n",
    "        D_j, d_m = similarity(ind, self.X_f, indiv=True)\n",
    "        return D_j\n",
    "    \n",
    "\n",
    "def extract_XY_global_pairs(T_in):\n",
    "    '''\n",
    "    This function reads a table 'T' of length 'n' and returns an\n",
    "    array of its X_global,Y_global coordinates in the form:\n",
    "    \n",
    "            [x1, y1]\n",
    "            [x2, y2]\n",
    "            [x3, y3]\n",
    "            ...\n",
    "            ...\n",
    "            [xn, yn]\n",
    "    '''\n",
    "    return np.vstack( (T_in['X_global'] , T_in['Y_global']) ).T\n",
    "\n",
    "def calculate_medians(T_d,T_d_ind_mean, T_d_ind_std, cell_type = True, k=50):\n",
    "    \n",
    "    names = [name for name in T_d.colnames if len(T_d[name].shape) <= 1]\n",
    "    df = T_d[names].to_pandas()   \n",
    "    names_v = [name for name in T_d.colnames if len(T_d[name].shape) <= 1]\n",
    "    names_v2 = [name for name in names_v if np.array(T_d[name]).dtype == '>f4']\n",
    "    names_v2 = names_v2[2:]\n",
    "    features = T_d.colnames[:-2] \n",
    "    \n",
    "    df_mean = T_d_ind_mean[names_v2]\n",
    "    df_std = T_d_ind_std[names_v2]    \n",
    "    print(df_mean)\n",
    "    \n",
    "    if cell_type == True:    \n",
    "        cell_types = [0,1,2,3]\n",
    "        rho_cells_medians=[]\n",
    "        S_mean_cells_medians=[]\n",
    "        S_std_cells_medians=[]\n",
    "\n",
    "        \n",
    "        print('shape d_mean', df_mean.shape)\n",
    "        print('shape df', df.shape)\n",
    "        \n",
    "        if df_mean.empty==True:\n",
    "            print('EMPTY!')\n",
    "            Sf_mean_cells_medians=[np.zeros((46,1)) for i in cell_types]\n",
    "            Sf_std_cells_medians=[np.zeros((46,1)) for i in cell_types]\n",
    "        \n",
    "        else:\n",
    "            Sf_mean_cells_medians=[]\n",
    "            Sf_std_cells_medians=[]            \n",
    "            for key in cell_types:\n",
    "                if key in np.unique(T_d['cell_type_SVM']):        \n",
    "                    #Ali's density measure\n",
    "                    rho_cells_medians.append(df.loc[df['cell_type_SVM'].eq(key),'density_cell_type_knn_'+str(k)].median())\n",
    "                    #New similarity measure\n",
    "                    S_mean_cells_medians.append(df.loc[df['cell_type_SVM'].eq(key),'mean_alldensity_cell_type_knn_'+str(k)].median() )\n",
    "                    S_std_cells_medians.append(df.loc[df['cell_type_SVM'].eq(key),'std_alldensity_cell_type_knn_'+str(k)].median())\n",
    "        \n",
    "                    Sf_mean_cells_medians.append(df_mean.loc[df['cell_type_SVM'].eq(key)].median())\n",
    "                    Sf_std_cells_medians.append(df_std.loc[df['cell_type_SVM'].eq(key)].median())\n",
    "                else:\n",
    "                    print('there are no cells of type ',key)\n",
    "                    rho_cells_medians.append(0)\n",
    "                    S_mean_cells_medians.append(0)\n",
    "                    S_std_cells_medians.append(0)\n",
    "                    Sf_mean_cells_medians.append(np.zeros_like(df_mean.loc[df['cell_type_SVM']].median())) \n",
    "                    Sf_std_cells_medians.append(np.zeros_like(df_mean.loc[df['cell_type_SVM']].median()))\n",
    "\n",
    "    return rho_cells_medians, S_mean_cells_medians, S_std_cells_medians, Sf_mean_cells_medians, Sf_std_cells_medians\n",
    "\n",
    "\n",
    "\n",
    "def add_density(T, bandwidth = 50):\n",
    "    \n",
    "    T = T[ T['overlap'] != True ]\n",
    "    T_mean = T[ T['overlap'] != True ]\n",
    "    T_std = T[ T['overlap'] != True ]\n",
    "   \n",
    "    names_ = [name for name in T.colnames if np.array(T[name]).dtype == '>f4']\n",
    "    T_mean_2 = pd.DataFrame(np.array(T), columns = names_ )\n",
    "    T_std_2 = pd.DataFrame(np.array(T), columns = names_ )\n",
    "\n",
    "    bandwidth_list=[bandwidth]\n",
    "    oc_cellType_objType_colname='cell_type_SVM'\n",
    "    kernel_list = ['knn']\n",
    "    unique_prefix_keyword_density = 'density_cell_type_'\n",
    "    \n",
    "\n",
    "    for bandwidth in bandwidth_list:\n",
    "        for kernel in kernel_list:\n",
    "            density_feature_name = unique_prefix_keyword_density + kernel + '_' + str( bandwidth)  # create density column name\n",
    "            new_mean_simil_all_feat = 'mean_all' + unique_prefix_keyword_density + kernel + '_' + str( bandwidth)  \n",
    "            new_std_simil_all_feat = 'std_all' + unique_prefix_keyword_density + kernel + '_' + str( bandwidth)  \n",
    "\n",
    "            T[density_feature_name] =   0.0      # add new 'density' column, i.e. 'density_feature_name'\n",
    "            T[new_mean_simil_all_feat] =   0.0 \n",
    "            T[new_std_simil_all_feat] =   0.0 \n",
    "            print('shape mean', T_mean.as_array().shape)\n",
    "            print('shape T',T.as_array().shape)\n",
    "            if oc_cellType_objType_colname in T.colnames:\n",
    "                T_objType = []\n",
    "                T_objType_index=[]\n",
    "                key_list=[]\n",
    "                i=0\n",
    "                print('num cell types',np.unique(T[oc_cellType_objType_colname]).shape[0])\n",
    "                cell_types = [0,1,2,3]\n",
    "                for key in cell_types:\n",
    "                    if key in np.unique(T[oc_cellType_objType_colname]):\n",
    "                        \n",
    "                        T_objType.append(T[ T[oc_cellType_objType_colname] == key ])  \n",
    "                        T_objType_index.append(np.where( T[oc_cellType_objType_colname] == key )[0])\n",
    "                        key_list.append(key)\n",
    "                        names = [name for name in T_objType[i].colnames if np.array(T_objType[i][name]).dtype == '>f4']\n",
    "\n",
    "                        X_=T_objType[i][names].to_pandas().values[:,:2]\n",
    "                        X_f=T_objType[i][names].to_pandas().values[:,2:]\n",
    "                        if len(T_objType[i]) > bandwidth   and     key != 0  :\n",
    "\n",
    "                        #  <----- condition.1 ------>        <--cond.2 -->\n",
    "                        # cond.1: put a lower-limit on the number of cells of a given type. \n",
    "                        # Currently it is set to the 'bandwidth'\n",
    "                        # cond.2: if key == 0, it is mark and therefore no need to estimate the density\n",
    "                        #  -------------------------------------------------------------\n",
    "                        # |  E s t i m a t e   K D E   D e n s i t y  ( in Log scale )  |\n",
    "                        #  -------------------------------------------------------------\n",
    "                        # Create an array consisitng of [X_global,Y_global] pairs only\n",
    "                            print(key)\n",
    "                            XY_global = extract_XY_global_pairs(T_objType[i])\n",
    "\n",
    "                        # based on astroML                        \n",
    "                            if kernel == 'knn':\n",
    "                                knd = KNeighborsDensity_modified(\"bayesian\", bandwidth ) \n",
    "                                # bayesian method (also can be used with 'simple' method)\n",
    "                                knd.fit(X_)\n",
    "                                log_density, dist = knd.eval(X_, X_f)\n",
    "                                dist_indiv_feat = knd.eval_indiv_feat(X_, X_f)\n",
    "                         # based on astroML    \n",
    "                            elif kernel == 'tophat' or kernel == 'gaussian':\n",
    "                                kde = KDE(kernel , h=bandwidth)\n",
    "                                kde.fit(XY_global)\n",
    "                                log_density = kde.eval(XY_global)\n",
    "                                # # # based on scikit-learn \n",
    "                                # # else:\n",
    "                                # #     # initialize a kernel object\n",
    "                                # #     kde_c = KernelDensity(bandwidth= bandwidth,  kernel=kernel).fit(XY_global)\n",
    "                                # #     \n",
    "                                # #     # estimate density in logarithmic scale\n",
    "                                # #     log_density = kde_c.score_samples(XY_global)    \n",
    "                                # populate the density column\n",
    "                             \n",
    "                            #Density and similarities all features\n",
    "                            T[density_feature_name][T_objType_index[i]] = log_density\n",
    "                            T[new_mean_simil_all_feat][T_objType_index[i]] = np.array(dist[0]).reshape(dist[0].shape[0])\n",
    "                            T[new_std_simil_all_feat][T_objType_index[i]] =  np.array(dist[1]).reshape(dist[0].shape[0])\n",
    "\n",
    "                            #Density and similarities individual features                            \n",
    "                            rows = T_objType_index[i]\n",
    "                            cols = names[2:]\n",
    "                            cols = np.arange(2,len(names))\n",
    "                            T_mean_2.iloc[rows,cols] = np.array(dist_indiv_feat)[0,:,:]\n",
    "                            T_std_2.iloc[rows,cols] = np.array(dist_indiv_feat)[1,:,:]                           \n",
    "                            i+=1\n",
    "                        \n",
    "                        else:\n",
    "                            print('Saving null values for marks/cell type ',i)\n",
    "\n",
    "                            T[density_feature_name][T_objType_index[i]] = 0\n",
    "                            T[new_mean_simil_all_feat][T_objType_index[i]] = 0\n",
    "                            T[new_std_simil_all_feat][T_objType_index[i]] = 0\n",
    "                            \n",
    "                            rows = T_objType_index[i]\n",
    "                            cols = names[2:]  \n",
    "                            cols = np.arange(2,len(names))\n",
    "                            \n",
    "                            T_mean_2.iloc[rows,cols] = np.zeros_like(T_mean_2.iloc[rows,cols] )\n",
    "                            T_std_2.iloc[rows,cols] = np.zeros_like(T_std_2.iloc[rows,cols] )                             \n",
    "\n",
    "                            i+=1\n",
    "                    else:\n",
    "                        print('There are no cells of type',i)\n",
    "                        T_objType.append(T[ T[oc_cellType_objType_colname] == key ])  \n",
    "                        T_objType_index.append(np.where( T[oc_cellType_objType_colname] == key )[0])\n",
    "                        key_list.append(key)\n",
    "                        names = [name for name in T_objType[i].colnames if np.array(T_objType[i][name]).dtype == '>f4']\n",
    "\n",
    "                        T[density_feature_name][T_objType_index[i]] = 0\n",
    "                        T[new_mean_simil_all_feat][T_objType_index[i]] = 0\n",
    "                        T[new_std_simil_all_feat][T_objType_index[i]] = 0\n",
    "\n",
    "                        T_mean[names[2:]][T_objType_index[i]] = np.zeros_like(np.array(T_objType[i][names]))\n",
    "                        T_std[names[2:]][T_objType_index[i]] = np.zeros_like(np.array(T_objType[i][names]))                     \n",
    "                        \n",
    "                        rows = T_objType_index[i]\n",
    "                        cols = names[2:]    \n",
    "                        cols = np.arange(2,len(names))\n",
    "                        T_mean_2.iloc[rows,cols] = np.zeros_like(np.array(T_objType[i][names[2:]]))\n",
    "                        T_std_2.iloc[rows,cols] = np.zeros_like(np.array(T_objType[i][names[2:]]))                        \n",
    "                        i+=1\n",
    "                  \n",
    "            else:\n",
    "                print (\" ---------------------------------------------\")\n",
    "                print (\"|  Input table has no column called '{}'  |\".format(oc_cellType_objType_colname))\n",
    "                print (\" ---------------------------------------------\")\n",
    "                \n",
    "    return T, T_mean_2, T_std_2\n",
    "\n",
    "\n",
    "\n",
    "def writer(header, data, filename, option):\n",
    "        with open (filename, \"w\", newline = \"\") as csvfile:\n",
    "            if option == \"write\":\n",
    "\n",
    "                catalogs = csv.writer(csvfile, delimiter=\",\")\n",
    "                catalogs.writerow(header)\n",
    "                for x in data:\n",
    "                    catalogs.writerow(x)\n",
    "            elif option == \"update\":\n",
    "                writer = csv.DictWriter(csvfile, fieldnames = header, delimiter=\",\")\n",
    "                writer.writeheader()\n",
    "                writer.writerows(data)\n",
    "            else:\n",
    "                print(\"Option is not known\")\n",
    "\n",
    "\n",
    "def updater(filename):\n",
    "    with open(filename, newline= \"\") as file:\n",
    "        readData = [row for row in csv.DictReader(file)]\n",
    "\n",
    "\n",
    "    readHeader = readData[0].keys()\n",
    "    writer(readHeader, readData, filename, \"update\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
